{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d26144e",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0b36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4d726",
   "metadata": {},
   "source": [
    "# Set Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e1312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uning: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(77)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(77)\n",
    "print(f\"uning: {device}\")\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "num_epoch = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d23d93",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacb9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mnist(batch_size=batch_size, image_size=28):\n",
    "#     #download data\n",
    "#     mnist_train = dset.MNIST(root = 'MNIST_data/',\n",
    "#                              train=True, # train data로 download\n",
    "#                              transform=transforms.Compose([\n",
    "#                                  transforms.ToTensor(),\n",
    "#                                  transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "#                              ]),\n",
    "#                              target_transform=None,\n",
    "#                              download=True)\n",
    "\n",
    "#     mnist_test = dset.MNIST(root = 'MNIST_data/',\n",
    "#                              train=False, \n",
    "#                              transform=transforms.Compose([\n",
    "#                                  transforms.ToTensor(),\n",
    "#                                  transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "#                              ]),\n",
    "#                              target_transform=None,\n",
    "#                              download=True)\n",
    "\n",
    "#     train_loader = DataLoader(mnist_train,\n",
    "#                               batch_size=batch_size,\n",
    "#                               shuffle=True,\n",
    "#                               drop_last=True,\n",
    "#                               num_workers=8) # data processing에 할당하는 cpu core수\n",
    "\n",
    "#     test_loader = DataLoader(mnist_test,\n",
    "#                              batch_size=batch_size,\n",
    "#                              shuffle=True,\n",
    "#                              drop_last=True,\n",
    "#                              num_workers=8)\n",
    "    \n",
    "#     return (train_loader, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "def get_alphabet(root: str, batch_size: int):\n",
    "    \n",
    "    train_path = os.path.join(root, 'train')\n",
    "    test_path = os.path.join(root, 'test')\n",
    "    \n",
    "    alphabet_train1 = ImageFolder(root = train_path,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "#                                      transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "                                     transforms.Grayscale(1),\n",
    "                                     transforms.RandomRotation(5),\n",
    "                                     transforms.RandomInvert()\n",
    "                                 ]),\n",
    "                                 target_transform=None)\n",
    "    \n",
    "    alphabet_train2 = ImageFolder(root = train_path,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "#                                     transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "                                     transforms.Grayscale(1)\n",
    "                                 ]),\n",
    "                                 target_transform=None)\n",
    "    \n",
    "    alphabet_train3 = ImageFolder(root = train_path,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "#                                     transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "                                     transforms.Grayscale(1),\n",
    "                                     transforms.CenterCrop(20),\n",
    "                                     transforms.Resize(28)\n",
    "                                 ]),\n",
    "                                 target_transform=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    alphabet_test = ImageFolder(root = test_path,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "#                                      transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "                                     transforms.Grayscale(1)\n",
    "                                 ]),\n",
    "                                 target_transform=None)\n",
    "    \n",
    "    train_loader = DataLoader(alphabet_train1,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              num_workers=8)\n",
    "\n",
    "    test_loader = DataLoader(alphabet_test,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             num_workers=8) \n",
    "    \n",
    "    return (train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959ec92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_root = './data'\n",
    "train_loader, test_loader = get_alphabet(root = dset_root, batch_size = batch_size)\n",
    "#get_mnist()\n",
    "#get_alphabet(root = dset_root, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d9387",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b716f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, target = train_loader.__getitem__(100)\n",
    "# img = transforms.ToPILImage()\n",
    "# print(train_loader.class_to_index)\n",
    "# print(f\"shape: {img.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3385e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=128*4*4, out_features=1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 26)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f21c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "# train1_2_ pretrained\n",
    "\n",
    "# model = torch.load(\"./weights/alphabet_45ep_0.9461762309074402.pth\").to(device)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-1)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4342c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     path = \"./weights/AdamW_alphabet_47ep_0.0013882338535040617.pth\"\n",
    "#     test_model = torch.load(path)\n",
    "#     test_model.eval()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            x = image.to(device)\n",
    "            y_= label.to(device)\n",
    "\n",
    "            output = test_model.forward(x)\n",
    "            _, output_index = torch.max(output, 1)\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (output_index == y_).sum().float()\n",
    "\n",
    "        return f\"{100.0*correct/total}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0b4401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-80fd810d7cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"./weights/AdamW_alphabet_{i}ep_{accuarcy[i]}.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for i in range(1, num_epoch+1):\n",
    "#     for _,[image,label] in tqdm(enumerate(train_loader)):\n",
    "    for _,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accuracy.append(accuracy(model, test_loader))\n",
    "    if (np.max(accuracy) <= accuracy[i]):\n",
    "        path = f\"./weights/AdamW_alphabet_{i}ep_{accuarcy[i]}.pth\"\n",
    "        torch.save(model, path)\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    print(f\"Epoch: {i}, Loss: {loss.item()}, LR: {scheduler.optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244cc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.min(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vonenet",
   "language": "python",
   "name": "vonenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
